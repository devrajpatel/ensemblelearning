# ensemblelearning
We propose an efficient oversampling strategy based on transformer model GPT-2 along with the Synthetic Minority Over-sampling Technique (SMOTE) to tackle data imbalance and data insufficiency issues in the MBTI kaggle dataset. We compared the performance of different word embedding techniques along with different ML classifiers to select a suitable word embedding technique with a suitable ML approach for solving the personality recognition problem.
This comprehensive approach not only meets the specific requirements of accurately predicting personality through online interactions but also establishes a strong framework for predicting MBTI traits, crucial for optimizing team dynamics in both civilian and military environments.
