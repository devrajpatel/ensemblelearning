{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devra\\anaconda3\\envs\\dev1\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\devra\\AppData\\Local\\Temp\\ipykernel_19736\\776927324.py:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  evaluation_df = pd.concat([evaluation_df, pd.DataFrame({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\devra\\\\Downloads\\\\voting_results\\\\Voting_SMOTE_E-I.sav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devra\\anaconda3\\envs\\dev1\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\devra\\\\Downloads\\\\voting_results\\\\Voting_SMOTE_N-S.sav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devra\\anaconda3\\envs\\dev1\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\devra\\\\Downloads\\\\voting_results\\\\Voting_SMOTE_F-T.sav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devra\\anaconda3\\envs\\dev1\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\\\devra\\\\Downloads\\\\voting_results\\\\Voting_SMOTE_J-P.sav\n",
      "  Target  Accuracy  Precision    Recall  F1-Score   Roc-AUC\n",
      "0    E-I  0.878652   0.933219  0.815868  0.870607  0.878699\n",
      "1    N-S  0.939485   0.911232  0.977965  0.943420  0.938223\n",
      "2    F-T  0.798722   0.829508  0.773700  0.800633  0.799894\n",
      "3    J-P  0.785782   0.829670  0.719733  0.770801  0.785846\n"
     ]
    }
   ],
   "source": [
    "###Boosting-Voting Model with SMOTE and Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "ROOT = r\"C:\\\\Users\\\\devra\\\\Downloads\\\\Codes_PhD\"\n",
    "DATA_DIR = rf\"{ROOT}\\\\dataset\\\\bvclassifier\"\n",
    "MBTI_RAW_CSV_PATH = os.path.join(DATA_DIR, \"mbti_clean_biTri.csv\")\n",
    "MODEL = rf\"{ROOT}\\\\models\\\\trained_ml_0603\\\\\"\n",
    "OUTPUT = r\"D:\\\\devra\\\\Downloads\\\\voting_results\\\\\"\n",
    "\n",
    "data = pd.read_csv(MBTI_RAW_CSV_PATH)\n",
    "\n",
    "training_data = data[[\"cleaned_post\", \"E-I\", \"N-S\", \"F-T\", \"J-P\"]].copy()\n",
    "def make_dummies(data, columns=[\"E-I\", \"N-S\", \"F-T\", \"J-P\"]):\n",
    "    for column in columns:\n",
    "        temp_dummy = pd.get_dummies(data[column], prefix=\"type\")\n",
    "        data = data.join(temp_dummy)\n",
    "    return data\n",
    "training_data = make_dummies(training_data)\n",
    "\n",
    "X = training_data[[\"cleaned_post\"]]\n",
    "y = training_data.drop(columns=[\"cleaned_post\"])\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "vectorizer.fit(X[\"cleaned_post\"])\n",
    "X_transformed = vectorizer.transform(X[\"cleaned_post\"])\n",
    "\n",
    "y_columns = [\"E-I\", \"N-S\", \"F-T\", \"J-P\"]\n",
    "evaluation_df = pd.DataFrame(columns=[\"Target\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Roc-AUC\"])\n",
    "\n",
    "for target_name in y_columns:\n",
    "    y_target = y[f\"type_{target_name[0]}\"]\n",
    "    \n",
    "    X_over, y_over = smote.fit_resample(X_transformed, y_target)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "    base_models = [(name, pickle.load(open(f'{MODEL}{name}_{target_name}.sav', 'rb'))) for name in [\"NaiveBayes\",\"DecisionTree\",\n",
    "                                                                                                    \"RandomForest\", \"Xgboost\",\n",
    "                                                                                                    \"AdaBoost\",\"LogisticRegression\"]]\n",
    "    voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "    \n",
    "    # Fit the VotingClassifier\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predictions for the test data\n",
    "    voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the ensemble\n",
    "    accuracy = metrics.accuracy_score(y_test, voting_pred)\n",
    "    precision = metrics.precision_score(y_test, voting_pred)\n",
    "    recall = metrics.recall_score(y_test, voting_pred)\n",
    "    f1_score = metrics.f1_score(y_test, voting_pred)\n",
    "    roc_auc_score = metrics.roc_auc_score(y_test, voting_pred)\n",
    "\n",
    "    # Update the evaluation_df DataFrame\n",
    "    evaluation_df = pd.concat([evaluation_df, pd.DataFrame({\n",
    "        \"Target\": [target_name],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1-Score\": [f1_score],\n",
    "        \"Roc-AUC\": [roc_auc_score]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # Save the Voting Classifier\n",
    "    voting_filename = f'{OUTPUT}Voting_SMOTE_{target_name}.sav'\n",
    "    print(voting_filename)\n",
    "    pickle.dump(voting_clf, open(voting_filename, 'wb'))\n",
    "\n",
    "# Save the evaluation_df to a CSV file\n",
    "evaluation_df.to_csv(os.path.join(OUTPUT, 'evaluation_voting_SMOTE.csv'), index=False)\n",
    "print(evaluation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devra\\AppData\\Local\\Temp\\ipykernel_8216\\3926113638.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "###Boosting-Voting Model with SMOTE and Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import VotingClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "ROOT = r\"C:\\\\Users\\\\devra\\\\Downloads\\\\Codes_PhD\"\n",
    "DATA_DIR = rf\"{ROOT}\\\\dataset\\\\bvclassifier\"\n",
    "MBTI_RAW_CSV_PATH = os.path.join(DATA_DIR, \"mbti_clean_biTri.csv\")\n",
    "MODEL = rf\"{ROOT}\\\\models\\\\trained_ml_0603\\\\\"\n",
    "OUTPUT = r\"D:\\\\devra\\\\Downloads\\\\voting_results\\\\\"\n",
    "\n",
    "data = pd.read_csv(MBTI_RAW_CSV_PATH)\n",
    "\n",
    "training_data = data[[\"cleaned_post\", \"E-I\", \"N-S\", \"F-T\", \"J-P\"]].copy()\n",
    "def make_dummies(data, columns=[\"E-I\", \"N-S\", \"F-T\", \"J-P\"]):\n",
    "    for column in columns:\n",
    "        temp_dummy = pd.get_dummies(data[column], prefix=\"type\")\n",
    "        data = data.join(temp_dummy)\n",
    "    return data\n",
    "training_data = make_dummies(training_data)\n",
    "\n",
    "X = training_data[[\"cleaned_post\"]]\n",
    "y = training_data.drop(columns=[\"cleaned_post\"])\n",
    "\n",
    "oversample = RandomOverSampler()\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "vectorizer.fit(X[\"cleaned_post\"])\n",
    "X_transformed = vectorizer.transform(X[\"cleaned_post\"])\n",
    "\n",
    "y_columns = [\"E-I\", \"N-S\", \"F-T\", \"J-P\"]\n",
    "evaluation_df = pd.DataFrame(columns=[\"Target\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Roc-AUC\"])\n",
    "\n",
    "for target_name in y_columns:\n",
    "    y_target = y[f\"type_{target_name[0]}\"]\n",
    "    \n",
    "    X_over, y_over = oversample.fit_resample(X_transformed, y_target)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_over, y_over, test_size=0.2, random_state=42)\n",
    "\n",
    "    base_models = [(name, pickle.load(open(f'{MODEL}{name}_{target_name}.sav', 'rb'))) for name in [\"NaiveBayes\",\"DecisionTree\",\n",
    "                                                                                                    \"RandomForest\", \"Xgboost\",\n",
    "                                                                                                    \"AdaBoost\",\"LogisticRegression\"]]\n",
    "    voting_clf = VotingClassifier(estimators=base_models, voting='soft')\n",
    "    \n",
    "    # Fit the VotingClassifier\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Get the predictions for the test data\n",
    "    voting_pred = voting_clf.predict(X_test)\n",
    "\n",
    "    # Evaluate the ensemble\n",
    "    accuracy = metrics.accuracy_score(y_test, voting_pred)\n",
    "    precision = metrics.precision_score(y_test, voting_pred)\n",
    "    recall = metrics.recall_score(y_test, voting_pred)\n",
    "    f1_score = metrics.f1_score(y_test, voting_pred)\n",
    "    roc_auc_score = metrics.roc_auc_score(y_test, voting_pred)\n",
    "\n",
    "    # Update the evaluation_df DataFrame\n",
    "    evaluation_df = pd.concat([evaluation_df, pd.DataFrame({\n",
    "        \"Target\": [target_name],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1-Score\": [f1_score],\n",
    "        \"Roc-AUC\": [roc_auc_score]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "    # Save the Voting Classifier\n",
    "    voting_filename = f'{OUTPUT}Voting_Random_{target_name}.sav'\n",
    "    print(voting_filename)\n",
    "    pickle.dump(voting_clf, open(voting_filename, 'wb'))\n",
    "\n",
    "# Save the evaluation_df to a CSV file\n",
    "evaluation_df.to_csv(os.path.join(OUTPUT, 'evaluation_voting_Randomoversample.csv'), index=False)\n",
    "print(evaluation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
